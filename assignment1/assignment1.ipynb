{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas for csv data loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.preprocessing as pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Linear regression\n",
    "\n",
    "We are gonna use the Computer Hardware Data Set for this task, https://archive.ics.uci.edu/ml/datasets/Computer+Hardware\n",
    "\n",
    "![](pics/cpu.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor</th>\n",
       "      <th>name</th>\n",
       "      <th>MYCT</th>\n",
       "      <th>MMIN</th>\n",
       "      <th>MMAX</th>\n",
       "      <th>CACH</th>\n",
       "      <th>CHMIN</th>\n",
       "      <th>CHMAX</th>\n",
       "      <th>PRP</th>\n",
       "      <th>ERP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adviser</td>\n",
       "      <td>32/60</td>\n",
       "      <td>125</td>\n",
       "      <td>256</td>\n",
       "      <td>6000</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>269</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7a</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7b</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7c</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vendor     name  MYCT  MMIN   MMAX  CACH  CHMIN  CHMAX  PRP  ERP\n",
       "0  adviser    32/60   125   256   6000   256     16    128  198  199\n",
       "1   amdahl   470v/7    29  8000  32000    32      8     32  269  253\n",
       "2   amdahl  470v/7a    29  8000  32000    32      8     32  220  253\n",
       "3   amdahl  470v/7b    29  8000  32000    32      8     32  172  253\n",
       "4   amdahl  470v/7c    29  8000  16000    32      8     16  132  132"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/cpu_performance/machine.data').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 10 attribute:\n",
    "\n",
    "- vendor: is the name of the vender\n",
    "- name: many unique symbols\n",
    "- MYCT: machine cycle time in nanoseconds (integer)\n",
    "- MMIN: minimum main memory in kilobytes (integer)\n",
    "- MMAX: maximum main memory in kilobytes (integer)\n",
    "- CACH: cache memory in kilobytes (integer)\n",
    "- CHMIN: minimum channels in units (integer)\n",
    "- CHMAX: maximum channels in units (integer)\n",
    "- PRP: published relative performance (integer)\n",
    "- ERP: estimated relative performance from the original article (integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to use the first 8 attribute to predict the 9th attribute (which is the published relative performance)\n",
    "\n",
    "You will need to build a linear regression model for this task, by using MSE(mean square error) loss function, you are expected to get a loss lower than 6000 on you test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_regress (x_train, y_train,iters = 10000, step = 0.001):\n",
    "    theta = np.zeros(x_train.shape[1])\n",
    "    for i in range(iters):\n",
    "        h = np.dot(x_train, theta)\n",
    "        gradient = np.dot(h - y_train, x_train)/y_train.size\n",
    "        theta = theta - step * gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cpu_performance/machine.data')\n",
    "x1, x2, y = np.array(df.iloc[:,0:2]),np.array(df.iloc[:,2:-2]), np.array(df.iloc[:,-2])\n",
    "enc = pre.OneHotEncoder()\n",
    "x1 = enc.fit_transform(x1).toarray()\n",
    "x2_mean, y_mean = np.mean(x2,axis = 0), np.mean(y,axis = 0)\n",
    "x2_std, y_std = np.std(x2,axis = 0), np.std(y,axis = 0)\n",
    "x2,y = (x2 - x2_mean) / x2_std, (y - y_mean) / y_std\n",
    "x = np.concatenate((x1, x2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add constant column\n",
    "x_train = np.concatenate((np.ones((x_train.shape[0], 1)), x_train), axis=1)\n",
    "x_test = np.concatenate((np.ones((x_test.shape[0], 1)), x_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1593.9033341468166"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = Linear_regress(x_train,y_train)\n",
    "h_test = np.dot(x_test, theta)\n",
    "h_test_t = h_test * y_std + y_mean\n",
    "y_test_t = y_test * y_std + y_mean\n",
    "cost = ((h_test_t - y_test_t) ** 2 / 2).mean()\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1948.8204269476373"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_test = model.predict(x_test)\n",
    "h_test_t = h_test * y_std + y_mean\n",
    "y_test_t = y_test * y_std + y_mean\n",
    "cost = ((h_test_t - y_test_t) ** 2 / 2).mean()\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Logistic regression\n",
    "\n",
    "\n",
    "The dataset we are gonna use is Glass identification dataset from UCI Machine Learning repository https://archive.ics.uci.edu/ml/datasets/Glass+Identification\n",
    "![](pics/glass.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  class\n",
       "0   1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0      1\n",
       "1   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0      1\n",
       "2   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0      1\n",
       "3   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0      1\n",
       "4   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/glass_ident/glass.data').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 10 attributes:\n",
    "\n",
    "- id is a number representing the specific data point\n",
    "- RI is the refractive index\n",
    "- Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "- Mg: Magnesium\n",
    "- Al: Aluminum\n",
    "- Si: Silicon\n",
    "- K: Potassium\n",
    "- Ca: Calcium\n",
    "- Ba: Barium\n",
    "- Fe: Iron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 6 class, which is 1,2,3,5,6,7, NOTE THAT IN THIS DATASET THERE IS NO CLASS 4\n",
    "\n",
    "- 1 building_windows_float_processed\n",
    "- 2 building_windows_non_float_processed\n",
    "- 3 vehicle_windows_float_processed\n",
    "- 4 vehicle_windows_non_float_processed (None in this dataset)\n",
    "- 5 containers\n",
    "- 6 tableware\n",
    "- 7 headlamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have two sub-tasks on this dataset;\n",
    "\n",
    "1. Build a logistic regression model to classify class 2 and not class 2, i.e. a binary classifier to separate class 2 from everything else. This binary classifier should be able to get an accuracy higher than 85%\n",
    "2. Build a multiclass classification model by build 6 binary classifiers. This multiclass classifier should be able to get an accuracy higher than 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Policy\n",
    "\n",
    "You can use some high level library(PyTorch, TensorFlow, sklearn) to complete the tasks, But there will be **Bonus** if you use **Numpy** to implement the algorithms from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass, compute classifier output and cross entropy loss\n",
    "\n",
    "compute $h_{\\theta}(x)$\n",
    "$$\n",
    "h_{\\theta}(x)=\\frac{1}{1+e^{-\\theta^T x}}\n",
    "$$\n",
    "\n",
    "compute $J(\\theta)$\n",
    "\n",
    "$$\n",
    "J(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}Cost(h_{\\theta}(x^{(i)}),y^{(i)})\n",
    "$$\n",
    "\n",
    "compute $Cost(h_{\\theta}, y)$ (cross entropy)\n",
    "\n",
    "$$\n",
    "Cost(h_{\\theta}, y)=-y log((h_{\\theta}(x))-(1-y)log(1-(h_{\\theta}(x)))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass, compute gradients and update the classifier's weight\n",
    "\n",
    "compute the gradient\n",
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta}=\\sum_{i=1}^{m}(h_{\\theta}(x)-y^{(i)})x^{(i)}\n",
    "$$\n",
    "\n",
    "update the weights\n",
    "$$\n",
    "\\theta_{j}^{new}=\\theta_{j}^{old}-\\alpha\\frac{\\partial J(\\theta)}{\\partial \\theta}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_class(x_train, y_train,iters = 1000, step = 0.01):\n",
    "    theta = np.zeros(x_train.shape[1])\n",
    "    for i in range(iters):\n",
    "        # forward\n",
    "        h = 1 / (1 + np.exp(-np.dot(x_train, theta)))\n",
    "        cost = (-y_train * np.log(h)-(1 - y_train) * np.log(1 - h)).mean()\n",
    "        # backward\n",
    "        gradient = np.dot(h - y_train, x_train)/y_train.size\n",
    "        theta = theta - step * gradient\n",
    "        # display\n",
    "        #if i % 50 == 0:\n",
    "            #print('Iters', i, 'cost:', cost) \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/glass_ident/glass.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.array(df.iloc[:,1:-1]), np.array(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y != 3] = 0\n",
    "y[y == 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean,x_train_std = np.mean(x_train,axis = 0),np.std(x_train,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_train_mean) / x_train_std\n",
    "# add constant column\n",
    "x_train = np.concatenate((np.ones((x_train.shape[0], 1)), x_train), axis=1)\n",
    "x_test = np.concatenate((np.ones((x_test.shape[0], 1)), x_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = binary_class(x_train, y_train, 1000, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384615384615385"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_test = 1 / (1 + np.exp(-np.dot(x_test, theta1)))\n",
    "((h_test > 0.5) == y_test).sum() / y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification  using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "binary_model = LogisticRegression(random_state=0, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "binary_model.fit(x_train,y_train) \n",
    "# predict\n",
    "h_test = binary_model.predict_proba(x_test)\n",
    "h_test = h_test[:, 1]\n",
    "((h_test > 0.5) == y_test).sum() / y_test.size\n",
    "#print(binary_model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class(x_train, y_train):\n",
    "    num_class = list(range(1,8))\n",
    "    param = np.zeros((len(num_class), x_train.shape[1]))\n",
    "    \n",
    "    for i,line in enumerate(num_class):\n",
    "        label_t = np.zeros_like(y_train)\n",
    "        label_t[y_train == line] = 1\n",
    "        param[i, :] = binary_class(x_train, label_t,10000,0.0001)\n",
    "    \n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/glass_ident/glass.data')\n",
    "x, y = np.array(df.iloc[:,1:-1]), np.array(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean,x_train_std = np.mean(x_train,axis = 0),np.std(x_train,axis = 0)\n",
    "\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_train_mean) / x_train_std\n",
    "\n",
    "x_train = np.concatenate((np.ones((x_train.shape[0], 1)), x_train), axis=1)\n",
    "x_test = np.concatenate((np.ones((x_test.shape[0], 1)), x_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = multi_class(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_pred(param, x_test, y_test):\n",
    "    logits = np.dot(x_test, np.transpose(param)).squeeze()\n",
    "    prob = 1 / (1 + np.exp(-logits))\n",
    "    pred = np.argmax(prob, axis=1) + 1\n",
    "    accuracy = np.sum(pred == y_test) / y_test.shape[0] * 100\n",
    "    return prob, pred, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 1 2 2 1 7 2 1 1 1 1 2 1 5 1 7 7 2 1 7 2 1 7 2 1 2 2 1 1 1 2 1 1 7 7 1 2\n",
      " 7 1 1 2 1 2 7 2 7 1 7 1 1 1 2 2 5 1 1 2 7 1 1 1 2 1 7 7]\n",
      "\n",
      "Accuracy: 64.615%\n"
     ]
    }
   ],
   "source": [
    "_, preds, accu = multi_pred(params, x_test, y_test)\n",
    "print(\"Prediction: {}\\n\".format(preds))\n",
    "print(\"Accuracy: {:.3f}%\".format(accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification  using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "multi_model = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = multi_model.predict_proba(x_test)\n",
    "preds = np.argmax(proba, axis=1)+1\n",
    "preds[preds > 3] = preds[preds > 3]+1\n",
    "accu = np.sum(preds == y_test) / y_test.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 2 2 2 1 7 2 1 1 1 2 2 1 2 1 7 7 2 1 7 1 1 7 1 1 1 2 1 2 2 2 2 1 7 2 1 2\n",
      " 7 2 1 1 1 3 7 2 7 2 6 1 1 2 2 2 5 1 1 2 7 1 1 2 2 1 2 7]\n",
      "\n",
      "Accuracy: 63.077%\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: {}\\n\".format(preds))\n",
    "print(\"Accuracy: {:.3f}%\".format(accu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
